{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import wptools, wikipedia, re\n",
    "\n",
    "def checkAllAlpha(test_str):\n",
    "    for c in test_str:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def removeBracketsData(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    skip3c = 0\n",
    "    skip4c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == '{':\n",
    "            skip3c += 1\n",
    "        elif i == '<':\n",
    "            skip4c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif i == '}'and skip2c > 0:\n",
    "            skip3c -= 1\n",
    "        elif i == '>'and skip2c > 0:\n",
    "            skip4c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0 and skip3c == 0 and skip4c == 0 and i!=',':\n",
    "            ret += i\n",
    "    return ret.strip()\n",
    "\n",
    "def removeHTML(test_str):\n",
    "    ret = ''\n",
    "    skip4c = 0\n",
    "    for i in test_str:\n",
    "        if i == '<':\n",
    "            skip4c += 1\n",
    "        elif i == '>' and skip4c > 0:\n",
    "            skip4c -= 1\n",
    "        elif skip4c == 0:\n",
    "            ret += i\n",
    "    return ret.strip()\n",
    "\n",
    "def populate_data(company_name, company_data_dict):\n",
    "    # company_data_dict = wptools.page(wikipedia.search(company_name)[0]).get_parse(show=False).data['infobox']\n",
    "    # return company_data_dict\n",
    "    comp_data_to_store = {'name': company_name, 'type': '', 'industry': '', 'revenue': -1, 'operating_income': -1, 'net_income': -1, 'hq_location': '', 'num_employees': -1, 'founded': -1, 'website':'' }\n",
    "    try:\n",
    "        if 'name' in company_data_dict.keys():\n",
    "            comp_data_to_store['name'] = removeHTML(company_data_dict['name'])\n",
    "    except:\n",
    "        comp_data_to_store['name'] = company_name\n",
    "    try:\n",
    "        if 'type' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['type']\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                if len(token)>0:\n",
    "                    comp_data_to_store['type'] = token.split('|')[-1]\n",
    "                    break\n",
    "    except:\n",
    "        comp_data_to_store['type'] = ''\n",
    "    try:\n",
    "        if 'industry' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['industry']\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                token = token.strip()\n",
    "                if len(token)>0 and checkAllAlpha(token[0]):\n",
    "                    for tok in token.split('|'):\n",
    "                        if len(tok)>3:\n",
    "                            comp_data_to_store['industry'] = comp_data_to_store['industry']+ removeBracketsData(tok)+','\n",
    "            comp_data_to_store['industry'] = comp_data_to_store['industry'][:-1]\n",
    "    except:\n",
    "        comp_data_to_store['industry'] = ''\n",
    "    # print(4)\n",
    "    try:\n",
    "        if 'operating_income' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['operating_income']\n",
    "            index = -1\n",
    "            operating_income = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                operating_income = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                operating_income = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                operating_income = 1000\n",
    "            if operating_income>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['operating_income'] = float(num) * operating_income\n",
    "            else:\n",
    "                comp_data_to_store['operating_income'] = -1.0\n",
    "    except:\n",
    "        comp_data_to_store['operating_income'] = -1.0\n",
    "\n",
    "    try:\n",
    "        if 'net_income' in company_data_dict.keys() and '$' in company_data_dict['net_income']:\n",
    "            str_to_process = company_data_dict['net_income']\n",
    "            index = -1\n",
    "            net_income = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                net_income = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                net_income = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                net_income = 1000\n",
    "            if net_income>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['net_income'] = float(num) * net_income\n",
    "            else:\n",
    "                comp_data_to_store['net_income'] = -1.0\n",
    "    except:\n",
    "        comp_data_to_store['net_income'] = -1.0\n",
    "\n",
    "    try:\n",
    "        if 'revenue' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['revenue']\n",
    "            index = -1\n",
    "            revenue = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                revenue = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                revenue = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                revenue = 1000\n",
    "            if revenue>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['revenue'] = float(num) * revenue\n",
    "    except:\n",
    "        comp_data_to_store['revenue'] = -1.0\n",
    "    # print(5)\n",
    "    try:\n",
    "        if 'hq_location' in company_data_dict.keys():\n",
    "            str_to_process = removeHTML(company_data_dict['hq_location'])\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                token = token.strip()\n",
    "                if len(token)>0 and token[0].isalpha():\n",
    "                    for tok in token.split('|'):\n",
    "                        if len(tok)>0:\n",
    "                            comp_data_to_store['hq_location'] = comp_data_to_store['hq_location'] + tok + ' '\n",
    "            comp_data_to_store['hq_location'] = comp_data_to_store['hq_location'].strip()\n",
    "    except:\n",
    "        comp_data_to_store['hq_location'] = ''\n",
    "    # print(6)\n",
    "    try:\n",
    "        if 'num_employees' in company_data_dict.keys():\n",
    "            str_to_process = removeBracketsData(company_data_dict['num_employees'])\n",
    "            n_emp = 0\n",
    "            for c in str_to_process:\n",
    "                if c==',':\n",
    "                    continue\n",
    "                elif (not c.isdigit()) and n_emp>0:\n",
    "                    break\n",
    "                elif c.isdigit():\n",
    "                    n_emp = n_emp*10 + int(c)\n",
    "            comp_data_to_store['num_employees'] = n_emp\n",
    "    except:\n",
    "        comp_data_to_store['num_employees'] = 0\n",
    "    # print(7)\n",
    "    try:\n",
    "        if 'founded' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['founded']\n",
    "            list_of_tokens = re.findall(r'\\d{4}', str_to_process)\n",
    "            for year in list_of_tokens:\n",
    "                comp_data_to_store['founded'] = int(year)\n",
    "    except:\n",
    "        comp_data_to_store['founded'] = -1\n",
    "    # print(8)\n",
    "    try:\n",
    "        if 'website' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['website']\n",
    "            if '.com' in str_to_process:\n",
    "                index = str_to_process.index('.com')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.com'\n",
    "                # print(link+'.com')\n",
    "                # count+=1\n",
    "            elif '.io' in str_to_process:\n",
    "                index = str_to_process.index('.io')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.io'\n",
    "                # print(link+'.io')\n",
    "                # count+=1\n",
    "            elif '.ai' in str_to_process:\n",
    "                index = str_to_process.index('.ai')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.ai'\n",
    "                # print(link+'.ai')\n",
    "                # count+=1\n",
    "            elif '.org' in str_to_process:\n",
    "                index = str_to_process.index('.org')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.org'\n",
    "                # print(link+'.org')\n",
    "                # count+=1\n",
    "            elif '.us' in str_to_process:\n",
    "                index = str_to_process.index('.us')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.us'\n",
    "                # print(link+'.us')\n",
    "                # count+=1\n",
    "            elif '.net' in str_to_process:\n",
    "                index = str_to_process.index('.net')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.net'\n",
    "                # print(link+'.net')\n",
    "                # count+=1\n",
    "    except:\n",
    "        comp_data_to_store['website'] = ''\n",
    "\n",
    "    return comp_data_to_store"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "2051"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle, pandas as pd\n",
    "pageranksDF = pd.read_csv('pageranks.csv')\n",
    "domain_pagerank = {}\n",
    "for i, r in pageranksDF.iterrows():\n",
    "    try:\n",
    "        domain_pagerank[r['Domain'].strip()] = float(r['Page Rank Value'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "with open('company_url_dict_updated.pkl', 'rb') as f:\n",
    "    company_url_dict_updated = pickle.load(f)\n",
    "with open('company_wiki_infobox_data.pkl', 'rb') as f:\n",
    "    company_wiki_infobox_data = pickle.load(f)\n",
    "l = []\n",
    "count = 1\n",
    "for company_name, comp_data in company_wiki_infobox_data.items():\n",
    "    data = populate_data(company_name, comp_data)\n",
    "    if data is None:\n",
    "        continue\n",
    "    data['student_careers_url'] = company_url_dict_updated[company_name]\n",
    "    data['index_name'] = company_name\n",
    "    if data['website'] in domain_pagerank.keys():\n",
    "        data['pagerank'] = domain_pagerank[data['website'].strip()]\n",
    "    else:\n",
    "        data['pagerank'] = -1\n",
    "    l.append(data)\n",
    "    count+=1\n",
    "count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                     name     type               industry    revenue  \\\n0          [24]7.ai, Inc.  Private  Software and Services         -1   \n1               280 North                    web software         -1   \n2             2d3 Sensing                        software         -1   \n3                33Across                                         -1   \n4  3D Systems Corporation   Public             Technology  646840000   \n\n   operating_income  net_income           hq_location  num_employees  founded  \\\n0                -1          -1  San Jose, California          15000       -1   \n1                -1          -1                                   -1     2008   \n2                -1          -1    Irvine, California             -1     1999   \n3                -1          -1                                   -1     2008   \n4          65319999    66190000                                 2666       -1   \n\n         website                                student_careers_url  \\\n0         247.ai                 https://www.247.ai/company/careers   \n1                                https://angel.co/company/280-north   \n2                 https://www.usajobs.gov/Help/working-in-govern...   \n3   33across.com                  https://www.33across.com/careers/   \n4  3dsystems.com                  https://www.3dsystems.com/careers   \n\n        index_name  pagerank  \n0         (24)7.ai      5.68  \n1  280 North, Inc.     -1.00  \n2              2d3     -1.00  \n3         33Across      5.68  \n4       3D Systems      5.85  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>type</th>\n      <th>industry</th>\n      <th>revenue</th>\n      <th>operating_income</th>\n      <th>net_income</th>\n      <th>hq_location</th>\n      <th>num_employees</th>\n      <th>founded</th>\n      <th>website</th>\n      <th>student_careers_url</th>\n      <th>index_name</th>\n      <th>pagerank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>[24]7.ai, Inc.</td>\n      <td>Private</td>\n      <td>Software and Services</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>San Jose, California</td>\n      <td>15000</td>\n      <td>-1</td>\n      <td>247.ai</td>\n      <td>https://www.247.ai/company/careers</td>\n      <td>(24)7.ai</td>\n      <td>5.68</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>280 North</td>\n      <td></td>\n      <td>web software</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td></td>\n      <td>-1</td>\n      <td>2008</td>\n      <td></td>\n      <td>https://angel.co/company/280-north</td>\n      <td>280 North, Inc.</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2d3 Sensing</td>\n      <td></td>\n      <td>software</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>Irvine, California</td>\n      <td>-1</td>\n      <td>1999</td>\n      <td></td>\n      <td>https://www.usajobs.gov/Help/working-in-govern...</td>\n      <td>2d3</td>\n      <td>-1.00</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>33Across</td>\n      <td></td>\n      <td></td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td></td>\n      <td>-1</td>\n      <td>2008</td>\n      <td>33across.com</td>\n      <td>https://www.33across.com/careers/</td>\n      <td>33Across</td>\n      <td>5.68</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>3D Systems Corporation</td>\n      <td>Public</td>\n      <td>Technology</td>\n      <td>646840000</td>\n      <td>65319999</td>\n      <td>66190000</td>\n      <td></td>\n      <td>2666</td>\n      <td>-1</td>\n      <td>3dsystems.com</td>\n      <td>https://www.3dsystems.com/careers</td>\n      <td>3D Systems</td>\n      <td>5.85</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(l)\n",
    "df['revenue'] = df['revenue'].astype('int64', copy=False)\n",
    "df['net_income'] = df['net_income'].astype('int64', copy=False)\n",
    "df['operating_income'] = df['operating_income'].astype('int64', copy=False)\n",
    "df['founded'] = df['founded'].astype('int64', copy=False)\n",
    "df['num_employees'] = df['num_employees'].astype('int64', copy=False)\n",
    "df.head()\n",
    "# df.to_csv('companies_wikipedia_data.csv', index=False)\n",
    "# # import pickle\n",
    "# with open('wiki_dict.pkl', 'rb') as f:\n",
    "#     x = pickle.load(f)\n",
    "# wiki_data_populated = {}\n",
    "# count = 0\n",
    "# for k, v in x.items():\n",
    "#     d = populate_data(k)\n",
    "#     if d is None :\n",
    "#         continue\n",
    "#     wiki_data_populated[k] = d\n",
    "#     wiki_data_file = open(\"company_wiki_infobox_data.pkl\", \"wb\")\n",
    "#     pickle.dump(wiki_data_populated, wiki_data_file)\n",
    "#     wiki_data_file.close()\n",
    "#     count+=1\n",
    "#     if count%100==0:\n",
    "#         print(count)\n",
    "# populate_data('Apple (company)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import yfinance as yf\n",
    "# with open('wiki_data_populated.pkl', 'rb') as f:\n",
    "#     x = pickle.load(f)\n",
    "# with open('company_url_dict_updated.pkl', 'rb') as f:\n",
    "#     x2 = pickle.load(f)\n",
    "# with open('companies_best_match_symbol.pkl', 'rb') as f:\n",
    "#     companies_best_match_symbol = pickle.load(f)\n",
    "# import pandas as pd\n",
    "# row_list = []\n",
    "# for k, v in x.items():\n",
    "#     if 'data' in v.keys():\n",
    "#         continue\n",
    "#     v['index_name'] = k\n",
    "#     if v['index_name'] in companies_best_match_symbol.keys():\n",
    "#         v['stock_symbol'] = companies_best_match_symbol[v['index_name']]\n",
    "#         try:\n",
    "#             v['stock_price'] = yf.Ticker(v['stock_symbol']).history(period='1d').tail(1)['Close'].iloc[0]\n",
    "#         except:\n",
    "#             v['stock_price'] = 0\n",
    "#     v['student_careers_url'] = x2[k]\n",
    "#     row_list.append(v)\n",
    "# df = pd.DataFrame(row_list)\n",
    "# df['revenue'] = df['revenue'].astype('int64', copy=False)\n",
    "# df['founded'] = df['founded'].astype('int64', copy=False)\n",
    "# df['num_employees'] = df['num_employees'].astype('int64', copy=False)\n",
    "# df.head()\n",
    "# # df.to_csv('companies_wikipedia_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}