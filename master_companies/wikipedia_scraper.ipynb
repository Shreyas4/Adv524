{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import wptools, wikipedia, re\n",
    "\n",
    "def checkAllAlpha(test_str):\n",
    "    for c in test_str:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def removeBracketsData(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    skip3c = 0\n",
    "    skip4c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == '{':\n",
    "            skip3c += 1\n",
    "        elif i == '<':\n",
    "            skip4c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif i == '}'and skip2c > 0:\n",
    "            skip3c -= 1\n",
    "        elif i == '>'and skip2c > 0:\n",
    "            skip4c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0 and skip3c == 0 and skip4c == 0 and i!=',':\n",
    "            ret += i\n",
    "    return ret.strip()\n",
    "\n",
    "def removeHTML(test_str):\n",
    "    ret = ''\n",
    "    skip4c = 0\n",
    "    for i in test_str:\n",
    "        if i == '<':\n",
    "            skip4c += 1\n",
    "        elif i == '>' and skip4c > 0:\n",
    "            skip4c -= 1\n",
    "        elif skip4c == 0:\n",
    "            ret += i\n",
    "    return ret.strip()\n",
    "\n",
    "def populate_data(company_name, company_data_dict):\n",
    "    # company_data_dict = wptools.page(wikipedia.search(company_name)[0]).get_parse(show=False).data['infobox']\n",
    "    # return company_data_dict\n",
    "    comp_data_to_store = {'name': company_name, 'type': '', 'industry': '', 'revenue': -1, 'hq_location': '', 'num_employees': -1, 'founded': -1}\n",
    "    try:\n",
    "        if 'name' in company_data_dict.keys():\n",
    "            comp_data_to_store['name'] = removeHTML(company_data_dict['name'])\n",
    "    except:\n",
    "        comp_data_to_store['name'] = company_name\n",
    "    try:\n",
    "        if 'type' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['type']\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                if len(token)>0:\n",
    "                    comp_data_to_store['type'] = token.split('|')[-1]\n",
    "                    break\n",
    "    except:\n",
    "        comp_data_to_store['type'] = ''\n",
    "    try:\n",
    "        if 'industry' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['industry']\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                token = token.strip()\n",
    "                if len(token)>0 and checkAllAlpha(token[0]):\n",
    "                    for tok in token.split('|'):\n",
    "                        if len(tok)>3:\n",
    "                            comp_data_to_store['industry'] = comp_data_to_store['industry']+ removeBracketsData(tok)+','\n",
    "            comp_data_to_store['industry'] = comp_data_to_store['industry'][:-1]\n",
    "    except:\n",
    "        comp_data_to_store['industry'] = ''\n",
    "    # print(4)\n",
    "    try:\n",
    "        if 'revenue' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['revenue']\n",
    "            index = -1\n",
    "            revenue = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                revenue = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                revenue = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                revenue = 1000\n",
    "            if revenue>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['revenue'] = float(num) * revenue\n",
    "    except:\n",
    "        comp_data_to_store['revenue'] = -1.0\n",
    "    # print(5)\n",
    "    try:\n",
    "        if 'hq_location' in company_data_dict.keys():\n",
    "            str_to_process = removeHTML(company_data_dict['hq_location'])\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                token = token.strip()\n",
    "                if len(token)>0 and token[0].isalpha():\n",
    "                    for tok in token.split('|'):\n",
    "                        if len(tok)>0:\n",
    "                            comp_data_to_store['hq_location'] = comp_data_to_store['hq_location'] + tok + ' '\n",
    "            comp_data_to_store['hq_location'] = comp_data_to_store['hq_location'].strip()\n",
    "    except:\n",
    "        comp_data_to_store['hq_location'] = ''\n",
    "    # print(6)\n",
    "    try:\n",
    "        if 'num_employees' in company_data_dict.keys():\n",
    "            str_to_process = removeBracketsData(company_data_dict['num_employees'])\n",
    "            n_emp = 0\n",
    "            for c in str_to_process:\n",
    "                if c==',':\n",
    "                    continue\n",
    "                elif (not c.isdigit()) and n_emp>0:\n",
    "                    break\n",
    "                elif c.isdigit():\n",
    "                    n_emp = n_emp*10 + int(c)\n",
    "            comp_data_to_store['num_employees'] = n_emp\n",
    "    except:\n",
    "        comp_data_to_store['num_employees'] = 0\n",
    "    # print(7)\n",
    "    try:\n",
    "        if 'founded' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['founded']\n",
    "            list_of_tokens = re.findall(r'\\d{4}', str_to_process)\n",
    "            for year in list_of_tokens:\n",
    "                comp_data_to_store['founded'] = int(year)\n",
    "    except:\n",
    "        comp_data_to_store['founded'] = -1\n",
    "    # print(8)\n",
    "    try:\n",
    "        if 'website' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['website']\n",
    "            list_of_tokens = str_to_process.split('|')\n",
    "            for year in list_of_tokens:\n",
    "                if year[0]!='{':\n",
    "                    link = ''\n",
    "                    ix = 0\n",
    "                    while ix<len(year) and year[ix]!='}':\n",
    "                        link += year[ix]\n",
    "                        ix+=1\n",
    "                    comp_data_to_store['website'] = link\n",
    "                    break\n",
    "    except:\n",
    "        comp_data_to_store['website'] = ''\n",
    "    return comp_data_to_store"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "import pickle, pandas as pd\n",
    "with open('company_url_dict_updated.pkl', 'rb') as f:\n",
    "    company_url_dict_updated = pickle.load(f)\n",
    "with open('company_wiki_infobox_data.pkl', 'rb') as f:\n",
    "    company_wiki_infobox_data = pickle.load(f)\n",
    "l = []\n",
    "count = 1\n",
    "for company_name, comp_data in company_wiki_infobox_data.items():\n",
    "    data = populate_data(company_name, comp_data)\n",
    "    if data is None:\n",
    "        continue\n",
    "    data['student_careers_url'] = company_url_dict_updated[company_name]\n",
    "    data['index_name'] = company_name\n",
    "    l.append(data)\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        print(count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(l)\n",
    "df['revenue'] = df['revenue'].astype('int64', copy=False)\n",
    "df['founded'] = df['founded'].astype('int64', copy=False)\n",
    "df['num_employees'] = df['num_employees'].astype('int64', copy=False)\n",
    "df.head()\n",
    "df.to_csv('companies_wikipedia_data.csv', index=False)\n",
    "# import pickle\n",
    "# with open('wiki_dict.pkl', 'rb') as f:\n",
    "#     x = pickle.load(f)\n",
    "# wiki_data_populated = {}\n",
    "# count = 0\n",
    "# for k, v in x.items():\n",
    "#     d = populate_data(k)\n",
    "#     if d is None :\n",
    "#         continue\n",
    "#     wiki_data_populated[k] = d\n",
    "#     wiki_data_file = open(\"company_wiki_infobox_data.pkl\", \"wb\")\n",
    "#     pickle.dump(wiki_data_populated, wiki_data_file)\n",
    "#     wiki_data_file.close()\n",
    "#     count+=1\n",
    "#     if count%100==0:\n",
    "#         print(count)\n",
    "# populate_data('Apple (company)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import yfinance as yf\n",
    "# with open('wiki_data_populated.pkl', 'rb') as f:\n",
    "#     x = pickle.load(f)\n",
    "# with open('company_url_dict_updated.pkl', 'rb') as f:\n",
    "#     x2 = pickle.load(f)\n",
    "# with open('companies_best_match_symbol.pkl', 'rb') as f:\n",
    "#     companies_best_match_symbol = pickle.load(f)\n",
    "# import pandas as pd\n",
    "# row_list = []\n",
    "# for k, v in x.items():\n",
    "#     if 'data' in v.keys():\n",
    "#         continue\n",
    "#     v['index_name'] = k\n",
    "#     if v['index_name'] in companies_best_match_symbol.keys():\n",
    "#         v['stock_symbol'] = companies_best_match_symbol[v['index_name']]\n",
    "#         try:\n",
    "#             v['stock_price'] = yf.Ticker(v['stock_symbol']).history(period='1d').tail(1)['Close'].iloc[0]\n",
    "#         except:\n",
    "#             v['stock_price'] = 0\n",
    "#     v['student_careers_url'] = x2[k]\n",
    "#     row_list.append(v)\n",
    "# df = pd.DataFrame(row_list)\n",
    "# df['revenue'] = df['revenue'].astype('int64', copy=False)\n",
    "# df['founded'] = df['founded'].astype('int64', copy=False)\n",
    "# df['num_employees'] = df['num_employees'].astype('int64', copy=False)\n",
    "# df.head()\n",
    "# # df.to_csv('companies_wikipedia_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df.to_csv('companies_wikipedia_data.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}