{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import wptools, wikipedia, re\n",
    "\n",
    "def checkAllAlpha(test_str):\n",
    "    for c in test_str:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def removeBracketsData(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    skip3c = 0\n",
    "    skip4c = 0\n",
    "    for i in test_str:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == '{':\n",
    "            skip3c += 1\n",
    "        elif i == '<':\n",
    "            skip4c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif i == '}'and skip2c > 0:\n",
    "            skip3c -= 1\n",
    "        elif i == '>'and skip2c > 0:\n",
    "            skip4c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0 and skip3c == 0 and skip4c == 0 and i!=',':\n",
    "            ret += i\n",
    "    return ret.strip()\n",
    "\n",
    "def removeHTML(test_str):\n",
    "    ret = ''\n",
    "    skip4c = 0\n",
    "    for i in test_str:\n",
    "        if i == '<':\n",
    "            skip4c += 1\n",
    "        elif i == '>' and skip4c > 0:\n",
    "            skip4c -= 1\n",
    "        elif skip4c == 0:\n",
    "            ret += i\n",
    "    return ret.strip()\n",
    "\n",
    "def populate_data(company_name, company_data_dict):\n",
    "    # company_data_dict = wptools.page(wikipedia.search(company_name)[0]).get_parse(show=False).data['infobox']\n",
    "    # return company_data_dict\n",
    "    comp_data_to_store = {'name': company_name, 'type': '', 'industry': '', 'revenue': -1, 'operating_income': -1, 'net_income': -1, 'hq_location': '', 'num_employees': -1, 'founded': -1, 'website':'' }\n",
    "    try:\n",
    "        if 'name' in company_data_dict.keys():\n",
    "            comp_data_to_store['name'] = removeHTML(company_data_dict['name'])\n",
    "    except:\n",
    "        comp_data_to_store['name'] = company_name\n",
    "    try:\n",
    "        if 'type' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['type']\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                if len(token)>0:\n",
    "                    comp_data_to_store['type'] = token.split('|')[-1]\n",
    "                    break\n",
    "    except:\n",
    "        comp_data_to_store['type'] = ''\n",
    "    try:\n",
    "        if 'industry' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['industry']\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                token = token.strip()\n",
    "                if len(token)>0 and checkAllAlpha(token[0]):\n",
    "                    for tok in token.split('|'):\n",
    "                        if len(tok)>3:\n",
    "                            comp_data_to_store['industry'] = comp_data_to_store['industry']+ removeBracketsData(tok)+','\n",
    "            comp_data_to_store['industry'] = comp_data_to_store['industry'][:-1]\n",
    "    except:\n",
    "        comp_data_to_store['industry'] = ''\n",
    "    # print(4)\n",
    "    try:\n",
    "        if 'operating_income' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['operating_income']\n",
    "            index = -1\n",
    "            operating_income = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                operating_income = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                operating_income = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                operating_income = 1000\n",
    "            if operating_income>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['operating_income'] = float(num) * operating_income\n",
    "            else:\n",
    "                comp_data_to_store['operating_income'] = -1.0\n",
    "    except:\n",
    "        comp_data_to_store['operating_income'] = -1.0\n",
    "\n",
    "    try:\n",
    "        if 'net_income' in company_data_dict.keys() and '$' in company_data_dict['net_income']:\n",
    "            str_to_process = company_data_dict['net_income']\n",
    "            index = -1\n",
    "            net_income = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                net_income = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                net_income = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                net_income = 1000\n",
    "            if net_income>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['net_income'] = float(num) * net_income\n",
    "            else:\n",
    "                comp_data_to_store['net_income'] = -1.0\n",
    "    except:\n",
    "        comp_data_to_store['net_income'] = -1.0\n",
    "\n",
    "    try:\n",
    "        if 'revenue' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['revenue']\n",
    "            index = -1\n",
    "            revenue = 0\n",
    "            if 'million' in str_to_process:\n",
    "                index = str_to_process.index('million')\n",
    "                revenue = 1000000\n",
    "            elif 'billion' in str_to_process:\n",
    "                index = str_to_process.index('billion')\n",
    "                revenue = 1000000000\n",
    "            elif 'thousand' in str_to_process:\n",
    "                index = str_to_process.index('thousand')\n",
    "                revenue = 1000\n",
    "            if revenue>0:\n",
    "                num = ''\n",
    "                l = index-1\n",
    "                while l>=0 and str_to_process[l]!='$':\n",
    "                    if str_to_process[l].isdigit() or str_to_process[l]=='.':\n",
    "                        num = str_to_process[l] + num\n",
    "                    l-=1\n",
    "                comp_data_to_store['revenue'] = float(num) * revenue\n",
    "    except:\n",
    "        comp_data_to_store['revenue'] = -1.0\n",
    "    # print(5)\n",
    "    try:\n",
    "        if 'hq_location' in company_data_dict.keys():\n",
    "            str_to_process = removeHTML(company_data_dict['hq_location'])\n",
    "            list_of_tokens = re.findall(r'([^\\[\\]]*)', str_to_process)\n",
    "            for token in list_of_tokens:\n",
    "                token = token.strip()\n",
    "                if len(token)>0 and token[0].isalpha():\n",
    "                    for tok in token.split('|'):\n",
    "                        if len(tok)>0:\n",
    "                            comp_data_to_store['hq_location'] = comp_data_to_store['hq_location'] + tok + ' '\n",
    "            comp_data_to_store['hq_location'] = comp_data_to_store['hq_location'].strip()\n",
    "    except:\n",
    "        comp_data_to_store['hq_location'] = ''\n",
    "    # print(6)\n",
    "    try:\n",
    "        if 'num_employees' in company_data_dict.keys():\n",
    "            str_to_process = removeBracketsData(company_data_dict['num_employees'])\n",
    "            n_emp = 0\n",
    "            for c in str_to_process:\n",
    "                if c==',':\n",
    "                    continue\n",
    "                elif (not c.isdigit()) and n_emp>0:\n",
    "                    break\n",
    "                elif c.isdigit():\n",
    "                    n_emp = n_emp*10 + int(c)\n",
    "            comp_data_to_store['num_employees'] = n_emp\n",
    "    except:\n",
    "        comp_data_to_store['num_employees'] = 0\n",
    "    # print(7)\n",
    "    try:\n",
    "        if 'founded' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['founded']\n",
    "            list_of_tokens = re.findall(r'\\d{4}', str_to_process)\n",
    "            for year in list_of_tokens:\n",
    "                comp_data_to_store['founded'] = int(year)\n",
    "    except:\n",
    "        comp_data_to_store['founded'] = -1\n",
    "    # print(8)\n",
    "    try:\n",
    "        if 'website' in company_data_dict.keys():\n",
    "            str_to_process = company_data_dict['website']\n",
    "            if '.com' in str_to_process:\n",
    "                index = str_to_process.index('.com')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.com'\n",
    "                # print(link+'.com')\n",
    "                # count+=1\n",
    "            elif '.io' in str_to_process:\n",
    "                index = str_to_process.index('.io')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.io'\n",
    "                # print(link+'.io')\n",
    "                # count+=1\n",
    "            elif '.ai' in str_to_process:\n",
    "                index = str_to_process.index('.ai')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.ai'\n",
    "                # print(link+'.ai')\n",
    "                # count+=1\n",
    "            elif '.org' in str_to_process:\n",
    "                index = str_to_process.index('.org')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.org'\n",
    "                # print(link+'.org')\n",
    "                # count+=1\n",
    "            elif '.us' in str_to_process:\n",
    "                index = str_to_process.index('.us')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.us'\n",
    "                # print(link+'.us')\n",
    "                # count+=1\n",
    "            elif '.net' in str_to_process:\n",
    "                index = str_to_process.index('.net')\n",
    "                index-=1\n",
    "                link = ''\n",
    "                while str_to_process[index]!='.' and str_to_process[index]!='/' and str_to_process[index]!='|':\n",
    "                    link = str_to_process[index] + link\n",
    "                    index-=1\n",
    "                comp_data_to_store['website'] = link+'.net'\n",
    "                # print(link+'.net')\n",
    "                # count+=1\n",
    "    except:\n",
    "        comp_data_to_store['website'] = ''\n",
    "\n",
    "    return comp_data_to_store"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "2051"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle, pandas as pd\n",
    "pageranksDF = pd.read_csv('pageranks.csv')\n",
    "domain_pagerank = {}\n",
    "for i, r in pageranksDF.iterrows():\n",
    "    try:\n",
    "        domain_pagerank[r['Domain'].strip()] = float(r['Page Rank Value'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "with open('company_url_dict_updated.pkl', 'rb') as f:\n",
    "    company_url_dict_updated = pickle.load(f)\n",
    "with open('company_wiki_infobox_data.pkl', 'rb') as f:\n",
    "    company_wiki_infobox_data = pickle.load(f)\n",
    "l = []\n",
    "count = 1\n",
    "for company_name, comp_data in company_wiki_infobox_data.items():\n",
    "    data = populate_data(company_name, comp_data)\n",
    "    if data is None:\n",
    "        continue\n",
    "    data['student_careers_url'] = company_url_dict_updated[company_name]\n",
    "    data['index_name'] = company_name\n",
    "    if data['website'] in domain_pagerank.keys():\n",
    "        data['pagerank'] = domain_pagerank[data['website'].strip()]\n",
    "    else:\n",
    "        data['pagerank'] = -1\n",
    "    l.append(data)\n",
    "    count+=1\n",
    "count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(l)\n",
    "df['revenue'] = df['revenue'].astype('int64', copy=False)\n",
    "df['net_income'] = df['net_income'].astype('int64', copy=False)\n",
    "df['operating_income'] = df['operating_income'].astype('int64', copy=False)\n",
    "df['founded'] = df['founded'].astype('int64', copy=False)\n",
    "df['num_employees'] = df['num_employees'].astype('int64', copy=False)\n",
    "df.head()\n",
    "df.to_csv('companies_wikipedia_data.csv', index=False)\n",
    "# # import pickle\n",
    "# with open('wiki_dict.pkl', 'rb') as f:\n",
    "#     x = pickle.load(f)\n",
    "# wiki_data_populated = {}\n",
    "# count = 0\n",
    "# for k, v in x.items():\n",
    "#     d = populate_data(k)\n",
    "#     if d is None :\n",
    "#         continue\n",
    "#     wiki_data_populated[k] = d\n",
    "#     wiki_data_file = open(\"company_wiki_infobox_data.pkl\", \"wb\")\n",
    "#     pickle.dump(wiki_data_populated, wiki_data_file)\n",
    "#     wiki_data_file.close()\n",
    "#     count+=1\n",
    "#     if count%100==0:\n",
    "#         print(count)\n",
    "# populate_data('Apple (company)')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import yfinance as yf\n",
    "# with open('wiki_data_populated.pkl', 'rb') as f:\n",
    "#     x = pickle.load(f)\n",
    "# with open('company_url_dict_updated.pkl', 'rb') as f:\n",
    "#     x2 = pickle.load(f)\n",
    "# with open('companies_best_match_symbol.pkl', 'rb') as f:\n",
    "#     companies_best_match_symbol = pickle.load(f)\n",
    "# import pandas as pd\n",
    "# row_list = []\n",
    "# for k, v in x.items():\n",
    "#     if 'data' in v.keys():\n",
    "#         continue\n",
    "#     v['index_name'] = k\n",
    "#     if v['index_name'] in companies_best_match_symbol.keys():\n",
    "#         v['stock_symbol'] = companies_best_match_symbol[v['index_name']]\n",
    "#         try:\n",
    "#             v['stock_price'] = yf.Ticker(v['stock_symbol']).history(period='1d').tail(1)['Close'].iloc[0]\n",
    "#         except:\n",
    "#             v['stock_price'] = 0\n",
    "#     v['student_careers_url'] = x2[k]\n",
    "#     row_list.append(v)\n",
    "# df = pd.DataFrame(row_list)\n",
    "# df['revenue'] = df['revenue'].astype('int64', copy=False)\n",
    "# df['founded'] = df['founded'].astype('int64', copy=False)\n",
    "# df['num_employees'] = df['num_employees'].astype('int64', copy=False)\n",
    "# df.head()\n",
    "# # df.to_csv('companies_wikipedia_data.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}